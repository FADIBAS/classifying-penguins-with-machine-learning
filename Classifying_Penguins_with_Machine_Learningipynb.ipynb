{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "\n",
        "def clone_repo(repo_url):\n",
        "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
        "    if not os.path.exists(repo_name):\n",
        "        print(f\"Cloning repository from {repo_url}...\")\n",
        "        os.system(f\"git clone {repo_url}\")\n",
        "    else:\n",
        "        print(f\"Repository {repo_name} already cloned.\")\n",
        "    return repo_name\n",
        "\n",
        "# Clone the Penguins classification repository\n",
        "repo_url = \"https://github.com/ine-rmotr-projects/classifying-penguins-with-machine-learning.git\"\n",
        "repo_name = clone_repo(repo_url)\n",
        "\n",
        "# Load the dataset\n",
        "data_file = os.path.join(repo_name, \"penguins.csv\")\n",
        "if not os.path.exists(data_file):\n",
        "    raise FileNotFoundError(f\"Data file not found: {data_file}\")\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "\n",
        "# Preview the dataset\n",
        "print(\"Preview of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Basic information\n",
        "print(\"\\nDataset information:\")\n",
        "print(data.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "data['species'] = label_encoder.fit_transform(data['species'])\n",
        "\n",
        "data = pd.get_dummies(data, columns=['sex'], drop_first=True)\n",
        "\n",
        "# Feature selection\n",
        "X = data.drop(['species', 'island'], axis=1)  # Dropping 'island' as it is categorical and may not contribute significantly\n",
        "y = data['species']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Visualize feature importance\n",
        "feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
        "feature_importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6), title=\"Feature Importances\")\n",
        "plt.show()\n",
        "\n",
        "# Save the cleaned dataset (optional)\n",
        "output_file = os.path.join(repo_name, \"cleaned_penguins.csv\")\n",
        "data.to_csv(output_file, index=False)\n",
        "print(f\"Cleaned data saved to {output_file}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "aRRyxat6lYZt",
        "outputId": "984d11aa-9186-4697-bf87-a3d58a491f8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository from https://github.com/ine-rmotr-projects/RDP-health-and-obesity-trends.git...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Data file not found: RDP-health-and-obesity-trends/data/obesity-cleaned.csv",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4ecb1ae5b11b>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obesity-cleaned.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust path if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data file not found: {data_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Data file not found: RDP-health-and-obesity-trends/data/obesity-cleaned.csv"
          ]
        }
      ]
    }
  ]
}